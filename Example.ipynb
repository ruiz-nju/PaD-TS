{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35ed938d-1184-42a3-81f2-36261b12fcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sciclone/home/yli102/.conda/envs/PaD-TS/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "from resample import UniformSampler,Batch_Same_Sampler\n",
    "from Model import PaD_TS\n",
    "from diffmodel_init import create_gaussian_diffusion\n",
    "from training import Trainer\n",
    "from data_preprocessing.real_dataloader import CustomDataset\n",
    "from data_preprocessing.sine_dataloader import SineDataset\n",
    "from data_preprocessing.real_dataloader import fMRIDataset\n",
    "from data_preprocessing.mujoco_dataloader import MuJoCoDataset\n",
    "from torchsummary import summary\n",
    "from data_preprocessing.sampling import sampling\n",
    "from eval_run import discriminative_score,predictive_score,BMMD_score,BMMD_score_naive,VDS_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1349593-5978-41f1-a0e7-0ffd450a7c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'sine'\n",
    "if data == 'energy':\n",
    "    from configs.energy_config import Training_args, Model_args, Diffusion_args, DataLoader_args, Data_args\n",
    "elif data == 'stock':\n",
    "    from configs.stock_config import Training_args, Model_args, Diffusion_args, DataLoader_args, Data_args\n",
    "elif data == 'sine':\n",
    "    from configs.sine_config import Training_args, Model_args, Diffusion_args, DataLoader_args, Data_args\n",
    "else:\n",
    "    raise NotImplementedError(f\"Unkown Dataset: {args.data}\")\n",
    "    \n",
    "train_arg = Training_args()\n",
    "model_arg = Model_args()\n",
    "diff_arg = Diffusion_args()\n",
    "dl_arg = DataLoader_args()\n",
    "d_arg = Data_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "23b1428f-287f-467e-bc42-bf2119d458ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = CustomDataset(\n",
    "#             name=d_arg.name,\n",
    "#             proportion=d_arg.proportion,\n",
    "#             data_root=d_arg.data_root,\n",
    "#             window=d_arg.window,\n",
    "#             save2npy=d_arg.save2npy,\n",
    "#             neg_one_to_one=d_arg.neg_one_to_one,\n",
    "#             seed=d_arg.seed,\n",
    "#             period=d_arg.period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a9c5222-6644-4a7f-b291-eb4bc63f9fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling sine-dataset: 100%|██████████| 10000/10000 [00:01<00:00, 9943.14it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = SineDataset(\n",
    "            window=24,\n",
    "            num=d_arg.num,\n",
    "            dim=d_arg.dim,\n",
    "            save2npy=d_arg.save2npy,\n",
    "            neg_one_to_one=d_arg.neg_one_to_one,\n",
    "            seed=d_arg.seed,\n",
    "            period=d_arg.period\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54b052e8-6ae6-4fe3-83f3-6c0351786757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000000455140784"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.rawdata.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3336edba-7fa2-4727-bddd-b4128f558b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function:  MSE_MMD\n",
      "Save Directory:  ./OUTPUT/sine_24_MMD_save/\n",
      "Schedule Sampler:  batch\n",
      "Batch Size:  64\n",
      "Diffusion Steps:  250\n",
      "Epochs:  70000\n",
      "Alpha:  0.0005\n",
      "Window Size:  24\n",
      "Data shape:  (24, 5)\n",
      "Hidden:  128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                        batch_size=dl_arg.batch_size,\n",
    "                                        shuffle=dl_arg.shuffle,\n",
    "                                        num_workers=dl_arg.num_workers,\n",
    "                                        drop_last=dl_arg.drop_last,\n",
    "                                        pin_memory=dl_arg.pin_memory)\n",
    "model = PaD_TS(hidden_size=model_arg.hidden_size, \n",
    "               num_heads=model_arg.num_heads,\n",
    "               n_encoder=model_arg.n_encoder, \n",
    "               n_decoder=model_arg.n_decoder, \n",
    "               feature_last=model_arg.feature_last, \n",
    "               mlp_ratio=model_arg.mlp_ratio, \n",
    "               input_shape=model_arg.input_shape)\n",
    "diffusion = create_gaussian_diffusion(predict_xstart=diff_arg.predict_xstart,\n",
    "                                      diffusion_steps=diff_arg.diffusion_steps,\n",
    "                                      noise_schedule=diff_arg.noise_schedule,\n",
    "                                      loss=diff_arg.loss,\n",
    "                                      rescale_timesteps=diff_arg.rescale_timesteps)\n",
    "if train_arg.schedule_sampler == 'batch':\n",
    "    schedule_sampler = Batch_Same_Sampler(diffusion)\n",
    "elif train_arg.schedule_sampler == 'uniform':\n",
    "    schedule_sampler = UniformSampler(diffusion)\n",
    "else:\n",
    "    raise NotImplementedError(f\"Unkown sampler: {train_arg.schedule_sampler}\")\n",
    "    \n",
    "trainer = Trainer(model=model,\n",
    "                    diffusion=diffusion, \n",
    "                    data=dataloader, \n",
    "                    batch_size=dl_arg.batch_size,  \n",
    "                    lr = train_arg.lr,\n",
    "                    weight_decay = train_arg.weight_decay,\n",
    "                    lr_anneal_steps=train_arg.lr_anneal_steps,\n",
    "                    log_interval=train_arg.log_interval,\n",
    "                    save_interval=train_arg.save_interval,\n",
    "                    save_dir=train_arg.save_dir,\n",
    "                    schedule_sampler = schedule_sampler,\n",
    "                    mmd_alpha = train_arg.mmd_alpha)\n",
    "print('Loss Function: ',diff_arg.loss)\n",
    "print('Save Directory: ',train_arg.save_dir)\n",
    "print('Schedule Sampler: ',train_arg.schedule_sampler)\n",
    "print('Batch Size: ',dl_arg.batch_size)\n",
    "print('Diffusion Steps: ',diff_arg.diffusion_steps)\n",
    "print('Epochs: ',train_arg.lr_anneal_steps)\n",
    "print('Alpha: ',train_arg.mmd_alpha)\n",
    "print('Window Size: ',d_arg.window)\n",
    "print('Data shape: ',model_arg.input_shape)\n",
    "print('Hidden: ', model_arg.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb46a429-0340-40b1-91d7-cb4835b50b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Training======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mse: 0.039049, mmd: 0.000065, total: 0.039114:   0%|          | 49/10000 [00:03<12:27, 13.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m======Training======\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m======Done======\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/accepted/PaD-TS/training.py:77\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m loss_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, total: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(loss_str)\n\u001b[0;32m---> 77\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_anneal_lr()\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/sciclone/home/yli102/.conda/envs/PaD-TS/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sciclone/home/yli102/.conda/envs/PaD-TS/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('======Training======')\n",
    "trainer.train()\n",
    "print('======Done======')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9e68e7-ef96-437b-925f-6fa32885f6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Generate Samples======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [02:56<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./OUTPUT/sine_24_MMD_save/ddpm_fake_sine_24.npy\n",
      "======Diff Eval======\n",
      "======Discriminative Score======\n",
      "Fake data: min  0.26655108 , max  0.96131265\n",
      "Real data: min  0.5000000455140784 , max  0.9999999999995366\n",
      "0\n",
      "WARNING:tensorflow:From /home/yli102/accepted/PaD-TS/eval_utils/discriminative_metric.py:104: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /sciclone/home/yli102/.conda/envs/PaD-TS/lib/python3.8/site-packages/keras/layers/rnn/legacy_cells.py:588: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /sciclone/home/yli102/.conda/envs/PaD-TS/lib/python3.8/site-packages/keras/layers/rnn/legacy_cells.py:602: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/yli102/accepted/PaD-TS/eval_utils/discriminative_metric.py:108: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [00:36<00:00, 54.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:  0.5 , 1.0 , 1.0 \n",
      "\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [00:35<00:00, 55.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1:  0.5 , 1.0 , 1.0 \n",
      "\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  11%|█         | 214/2000 [00:04<00:35, 49.82it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m np_fake \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(concatenated_tensor\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m======Discriminative Score======\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdiscriminative_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_arg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp_fake\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_arg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m======Predictive Score======\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m predictive_score(d_arg\u001b[38;5;241m.\u001b[39mname,\u001b[38;5;241m5\u001b[39m, np_fake,length\u001b[38;5;241m=\u001b[39md_arg\u001b[38;5;241m.\u001b[39mwindow)\n",
      "File \u001b[0;32m~/accepted/PaD-TS/eval_run.py:49\u001b[0m, in \u001b[0;36mdiscriminative_score\u001b[0;34m(dataname, iterations, fake_data, length)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m---> 49\u001b[0m     temp_disc, fake_acc, real_acc, values \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminative_score_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mori_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mori_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     discriminative_score\u001b[38;5;241m.\u001b[39mappend(temp_disc)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m, temp_disc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, fake_acc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, real_acc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/accepted/PaD-TS/eval_utils/discriminative_metric.py:144\u001b[0m, in \u001b[0;36mdiscriminative_score_metrics\u001b[0;34m(ori_data, generated_data)\u001b[0m\n\u001b[1;32m    141\u001b[0m   X_hat_mb, T_hat_mb \u001b[38;5;241m=\u001b[39m batch_generator(train_x_hat, train_t_hat, batch_size)\n\u001b[1;32m    143\u001b[0m   \u001b[38;5;66;03m# Train discriminator\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m   _, step_d_loss \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md_solver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_loss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mX\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_hat\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_hat_mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_hat\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_hat_mb\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m## Test the performance on the testing set    \u001b[39;00m\n\u001b[1;32m    148\u001b[0m y_pred_real_curr, y_pred_fake_curr \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun([y_pred_real, y_pred_fake], \n\u001b[1;32m    149\u001b[0m                                               feed_dict\u001b[38;5;241m=\u001b[39m{X: test_x, T: test_t, X_hat: test_x_hat, T_hat: test_t_hat})\n",
      "File \u001b[0;32m/sciclone/home/yli102/.conda/envs/PaD-TS/lib/python3.8/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m/sciclone/home/yli102/.conda/envs/PaD-TS/lib/python3.8/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/sciclone/home/yli102/.conda/envs/PaD-TS/lib/python3.8/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m/sciclone/home/yli102/.conda/envs/PaD-TS/lib/python3.8/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1377\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1380\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m/sciclone/home/yli102/.conda/envs/PaD-TS/lib/python3.8/site-packages/tensorflow/python/client/session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1359\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1361\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sciclone/home/yli102/.conda/envs/PaD-TS/lib/python3.8/site-packages/tensorflow/python/client/session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('======Generate Samples======')\n",
    "concatenated_tensor = sampling(model,diffusion,dataset.sample_num,dataset.window, dataset.var_num, dl_arg.batch_size)\n",
    "np.save( f'{train_arg.save_dir}ddpm_fake_{d_arg.name}_{dataset.window}.npy', concatenated_tensor.cpu())\n",
    "print(f'{train_arg.save_dir}ddpm_fake_{d_arg.name}_{dataset.window}.npy')\n",
    "\n",
    "print('======Diff Eval======')\n",
    "np_fake = np.array(concatenated_tensor.detach().cpu())\n",
    "print('======Discriminative Score======')\n",
    "discriminative_score(d_arg.name,5, np_fake,length=d_arg.window)\n",
    "print('======Predictive Score======')\n",
    "predictive_score(d_arg.name,5, np_fake,length=d_arg.window)\n",
    "print('======VDS Score======')\n",
    "VDS_score(d_arg.name, concatenated_tensor,length=d_arg.window)\n",
    "print('======FDDS Score======')\n",
    "BMMD_score_naive(d_arg.name, concatenated_tensor,length=d_arg.window)\n",
    "print('======Finished======')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd69947-f02a-4654-8573-0eeca7d9ac5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaD-TS",
   "language": "python",
   "name": "pad-ts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
